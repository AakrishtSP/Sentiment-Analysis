{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk as nlt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/processed/facebook_grouped_preprocessed/posts_by_month.json\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Flatten into a single list of all posts\n",
    "all_posts = []\n",
    "for month, posts in json_data.items():\n",
    "    all_posts.extend(posts)  # Combine all posts into one list\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair</th>\n",
       "      <th>body</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>is it true hardly anyone uses facebook anymore...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>07:30:01</td>\n",
       "      <td>200</td>\n",
       "      <td>217</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "      <td>is it true hardly anyone uses facebook anymore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>found out how to customize what you see on fac...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>21:56:19</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>its not perfect but go to where your settings ...</td>\n",
       "      <td>found out how to customize what you see on fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>facebook groups are full of bots  scams and fa...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>19:00:24</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>does anyone else feel like facebook groups are...</td>\n",
       "      <td>facebook groups are full of bots  scams and fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>is there any point to hide allfrom the constan...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>15:14:16</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>when fb went to hell a month or two ago i thou...</td>\n",
       "      <td>is there any point to hide allfrom the constan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>why do things i post on someone elses timeline...</td>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>00:46:54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Tech Support</td>\n",
       "      <td>for the past couple of months when i post a bi...</td>\n",
       "      <td>why do things i post on someone elses timeline...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month                                              title        date  \\\n",
       "0  2025-03  is it true hardly anyone uses facebook anymore...  2025-03-05   \n",
       "1  2025-03  found out how to customize what you see on fac...  2025-03-05   \n",
       "2  2025-03  facebook groups are full of bots  scams and fa...  2025-03-05   \n",
       "3  2025-03  is there any point to hide allfrom the constan...  2025-03-05   \n",
       "4  2025-03  why do things i post on someone elses timeline...  2025-03-06   \n",
       "\n",
       "       time  score  num_comments         flair  \\\n",
       "0  07:30:01    200           217    Discussion   \n",
       "1  21:56:19      7            23    Discussion   \n",
       "2  19:00:24      8             8    Discussion   \n",
       "3  15:14:16     13            23    Discussion   \n",
       "4  00:46:54      1             2  Tech Support   \n",
       "\n",
       "                                                body  \\\n",
       "0                                                      \n",
       "1  its not perfect but go to where your settings ...   \n",
       "2  does anyone else feel like facebook groups are...   \n",
       "3  when fb went to hell a month or two ago i thou...   \n",
       "4  for the past couple of months when i post a bi...   \n",
       "\n",
       "                                       combined_text  \n",
       "0  is it true hardly anyone uses facebook anymore...  \n",
       "1  found out how to customize what you see on fac...  \n",
       "2  facebook groups are full of bots  scams and fa...  \n",
       "3  is there any point to hide allfrom the constan...  \n",
       "4  why do things i post on someone elses timeline...  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"combined_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Total character counts per post\n",
    "character_count = list(map(lambda x:len(x),text))\n",
    "\n",
    "df[\"character_count\"] = character_count\n",
    "\n",
    "# Total word count per post\n",
    "word_counts = list(map(lambda s: len(s.split()), text))\n",
    "df[\"Word_count\"] = word_counts\n",
    "\n",
    "# Seperated Words from total list\n",
    "words = [word.lower() for t in text for word in re.findall(r'\\b\\w+\\b', t)]\n",
    "# df[\"Sepeated_words\"] = words\n",
    "\n",
    "# Sepeated words PER list\n",
    "words_per_list = []\n",
    "for t in text:\n",
    "    words_per_list.append([text.lower() for text in re.findall(r'\\b\\w+\\b', t)])\n",
    "\n",
    "df[\"Seperated_List\"] = words_per_list\n",
    "\n",
    "# Frequncy of words in the entire dataframe\n",
    "word_freq_counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair</th>\n",
       "      <th>body</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>character_count</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Seperated_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>is it true hardly anyone uses facebook anymore...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>07:30:01</td>\n",
       "      <td>200</td>\n",
       "      <td>217</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "      <td>is it true hardly anyone uses facebook anymore...</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>[is, it, true, hardly, anyone, uses, facebook,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>found out how to customize what you see on fac...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>21:56:19</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>its not perfect but go to where your settings ...</td>\n",
       "      <td>found out how to customize what you see on fac...</td>\n",
       "      <td>357</td>\n",
       "      <td>68</td>\n",
       "      <td>[found, out, how, to, customize, what, you, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>facebook groups are full of bots  scams and fa...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>19:00:24</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>does anyone else feel like facebook groups are...</td>\n",
       "      <td>facebook groups are full of bots  scams and fa...</td>\n",
       "      <td>261</td>\n",
       "      <td>49</td>\n",
       "      <td>[facebook, groups, are, full, of, bots, scams,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>is there any point to hide allfrom the constan...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>15:14:16</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>when fb went to hell a month or two ago i thou...</td>\n",
       "      <td>is there any point to hide allfrom the constan...</td>\n",
       "      <td>452</td>\n",
       "      <td>90</td>\n",
       "      <td>[is, there, any, point, to, hide, allfrom, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>why do things i post on someone elses timeline...</td>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>00:46:54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Tech Support</td>\n",
       "      <td>for the past couple of months when i post a bi...</td>\n",
       "      <td>why do things i post on someone elses timeline...</td>\n",
       "      <td>421</td>\n",
       "      <td>83</td>\n",
       "      <td>[why, do, things, i, post, on, someone, elses,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month                                              title        date  \\\n",
       "0  2025-03  is it true hardly anyone uses facebook anymore...  2025-03-05   \n",
       "1  2025-03  found out how to customize what you see on fac...  2025-03-05   \n",
       "2  2025-03  facebook groups are full of bots  scams and fa...  2025-03-05   \n",
       "3  2025-03  is there any point to hide allfrom the constan...  2025-03-05   \n",
       "4  2025-03  why do things i post on someone elses timeline...  2025-03-06   \n",
       "\n",
       "       time  score  num_comments         flair  \\\n",
       "0  07:30:01    200           217    Discussion   \n",
       "1  21:56:19      7            23    Discussion   \n",
       "2  19:00:24      8             8    Discussion   \n",
       "3  15:14:16     13            23    Discussion   \n",
       "4  00:46:54      1             2  Tech Support   \n",
       "\n",
       "                                                body  \\\n",
       "0                                                      \n",
       "1  its not perfect but go to where your settings ...   \n",
       "2  does anyone else feel like facebook groups are...   \n",
       "3  when fb went to hell a month or two ago i thou...   \n",
       "4  for the past couple of months when i post a bi...   \n",
       "\n",
       "                                       combined_text  character_count  \\\n",
       "0  is it true hardly anyone uses facebook anymore...               74   \n",
       "1  found out how to customize what you see on fac...              357   \n",
       "2  facebook groups are full of bots  scams and fa...              261   \n",
       "3  is there any point to hide allfrom the constan...              452   \n",
       "4  why do things i post on someone elses timeline...              421   \n",
       "\n",
       "   Word_count                                     Seperated_List  \n",
       "0          14  [is, it, true, hardly, anyone, uses, facebook,...  \n",
       "1          68  [found, out, how, to, customize, what, you, se...  \n",
       "2          49  [facebook, groups, are, full, of, bots, scams,...  \n",
       "3          90  [is, there, any, point, to, hide, allfrom, the...  \n",
       "4          83  [why, do, things, i, post, on, someone, elses,...  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlt.download('stopwords',download_dir=\"/src/EDA\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['true', 'hardly', 'anyone', 'uses', 'facebook', 'anymore', 'becoming', 'relic', 'found', 'customize', 'see', 'facebook', 'without', 'extra', 'crap', 'perfect', 'go', 'settings', 'click', 'feeds', 'see', 'posts', 'actual', 'friends', 'groups', 'pages', 'follow', 'commenter', 'whos', 'gonna', 'say', 'delete', 'facebook', 'yes', 'youre', 'cool', 'unique', 'awesome', 'everyone', 'like', 'facebook', 'groups', 'full', 'bots', 'scams', 'fake', 'accounts', 'looking', 'rn', 'anyone', 'else', 'feel', 'like', 'facebook', 'groups', 'scam', 'like', 'im', 'trying', 'find', 'clients', 'facebook', '3', 'months', 'feel', 'everyone', 'scam', 'bots', 'fake', 'id', 'help', 'please', 'point', 'hide', 'allfrom', 'constant', 'barrage', 'fb', 'content', 'fb', 'went', 'hell', 'month', 'two', 'ago', 'thought', 'could', 'least', 'train', 'algorithm', 'little', 'telling', 'dont', 'want', 'see', 'ive', 'probably', 'hide', 'alld', 'couple', 'hundred', 'pages', 'still', 'bad', 'ever', 'honestly', 'would', 'delete', 'app', 'frequently', 'use', 'marketplace', 'buy', 'sell', 'appreciate', 'certain', 'community', 'updates', 'im', 'done', 'cruft', 'things', 'post', 'someone', 'elses', 'timeline', 'also', 'show', 'timeline', 'past', 'couple', 'months', 'post', 'birthday', 'friends', 'timeline', 'also', 'shows', 'timeline', 'making', 'look', 'like', 'screwed', 'posted', 'mistake', 'also', 'several', 'occasions', 'posted', 'image', 'duplicate', 'sometimes', '3', 'copies', 'posts', 'created', 'add', 'text', 'shows', 'idential', 'posts', 'others', 'saw', 'close', 'friends', 'story', 'checked', 'privacy', 'definitely', 'small', 'group', 'people', 'still', 'friends', 'list', 'refresh', 'list', 'sometimes', 'eliminates', 'others', 'sometimes', 'doesnt', 'anyone', 'else', 'problem', 'know', 'whats', 'going', 'want', 'know', 'facebook', 'messed', 'whats', 'going', 'person', 'poser', 'actually', 'true', 'human', 'facebook', 'link', 'facebook', 'account', 'find', 'instagram', 'account', 'facebook', 'bio', 'im', 'reaching', 'want', 'confirm', 'whether', 'real', 'person', 'anyone', 'personally', 'knows', 'would', 'really', 'appreciate', 'could', 'comment', 'would', 'help', 'reassure', 'indeed', 'claims', 'otherwise', 'cant', 'help', 'wonder', 'might', 'actually', 'someone', 'elseperhaps', 'even', 'completely', 'different', 'person', 'like', 'indian', 'man', 'pretending', 'online', 'ive', 'never', 'met', 'girl', 'person', 'randomly', 'added', 'facebook', 'first', 'later', 'noticed', 'also', 'following', 'instagram', 'account', 'immediately', 'raised', 'suspicions', 'naturally', 'anyone', 'common', 'sense', 'would', 'cautious', 'kind', 'behavior', 'curiosity', 'got', 'best', 'decided', 'talk', 'conversations', 'told', 'shes', '19', 'years', 'old', 'currently', 'living', 'manila', 'philippineswhich', 'interesting', 'also', 'live', 'philippines', 'meaning', 'relatively', 'close', 'however', 'something', 'feels', 'one', 'biggest', 'red', 'flags', 'refuses', 'answer', 'calls', 'even', 'though', 'weve', 'talking', 'two', 'weeks', 'whenever', 'ask', 'call', 'always', 'comes', 'excuse', 'avoid', 'example', 'said', 'oh', 'im', 'sorry', 'im', 'currently', 'mom', 'living', 'room', 'itd', 'awkward', 'calling', 'right', 'haha', 'might', 'sound', 'reasonable', 'twice', 'says', 'something', 'similar', 'every', 'time', 'bring', 'suspicious', 'things', 'get', 'bit', 'personal', 'weve', 'exchanged', 'intimate', 'pictures', 'otherincluding', 'photos', 'show', 'face', 'lets', 'realwho', 'right', 'mind', 'would', 'stranger', 'online', 'doesnt', 'seem', 'normal', 'makes', 'question', 'things', 'even', 'anyone', 'actually', 'knows', 'real', 'life', 'please', 'let', 'know', 'input', 'would', 'incredibly', 'helpful', 'ill', 'looking', 'forward', 'responses', 'thanks', 'advance', 'messenger', 'wont', 'play', 'videos', 'facebook', 'app', 'anymore', 'already', 'tried', 'fixes', 'today', 'updated', 'apps', 'may', 'broke', 'app', 'somehow', 'anyways', 'im', 'ios', 'buddy', 'send', 'clips', 'back', 'forth', 'today', 'guessing', 'updated', 'apps', 'facebook', 'wont', 'go', 'vid', 'click', 'messenger', 'click', 'vid', 'messenger', 'itll', 'open', 'facebook', 'sits', 'homepage', 'ive', 'tried', 'restarting', 'phone', 'turning', 'wifi', 'need', 'help', 'changing', 'businesses', 'facebook', 'page', 'type', 'shows', 'people', 'reason', 'look', 'business', 'facebook', 'page', 'link', 'says', 'facebookcompeoplebusiness', 'whereas', 'pages', 'facebookcombusiness', 'anyway', 'fix', 'thanks', 'way', 'permanently', 'remove', 'hate', 'speechbigotryrightwing', 'unwanted', 'content', 'facebook', 'feed', 'im', 'tired', 'clicking', 'interested', 'hide', 'x', 'every', 'time', 'hateful', 'content', 'appears', 'feed', 'dont', 'engage', 'posts', 'besides', 'hiding', 'dont', 'comment', 'dont', 'react', 'hell', 'dont', 'even', 'open', 'know', 'kinda', 'algorithm', 'works', 'ok', 'hide', 'kind', 'posts', 'keep', 'coming', 'back', 'different', 'pages', 'hide', 'posts', 'particular', 'page', 'sudden', 'im', 'bombarded', 'hateful', 'content', 'another', 'five', 'pages', 'havent', 'blocked', 'yet', 'wouldnt', 'really', 'mind', 'rightwing', 'suggested', 'content', 'wasnt', 'sexist', 'racist', 'homophobic', 'transphobic', 'types', 'hateful', 'memes', 'cater', 'values', 'something', 'intentional', 'facebook', 'part', 'algorithm', 'really', 'think', 'im', '60', 'years', 'old', 'trump', 'supporter', 'posting', 'facebook', 'combat', 'fox', 'news', 'newsmax', 'white', 'house', 'good', 'fake', 'account', 'facebook', 'use', 'combat', 'propaganda', 'right', 'wing', 'news', 'organizations', 'spread', 'make', 'abundantly', 'clear', 'fake', 'account', 'look', 'electronic', 'graffiti', 'comment', 'posts', 'trumps', 'meme', 'coin', 'rug', 'pull', 'january', '6th', 'insurrection', 'big', 'lie', 'example', 'get', 'occasional', 'go', 'away', 'troll', 'hope', 'maybe', 'one', 'person', 'see', 'wool', 'pulled', 'eyes', 'anyone', 'else', 'tried', 'take', 'right', 'wing', 'propaganda', 'machine', 'way', 'importantly', 'think', 'might', 'harm', 'good', 'way', 'laidoff', 'meta', 'employees', 'blast', 'zuckerberg', 'forums', 'running', 'cruelest', 'tech', 'company', 'dad', 'keeps', 'posting', 'pictures', 'baby', 'public', 'facebook', 'without', 'consent', 'get', 'dads', 'facebook', 'posts', 'baby', 'deleted', 'keeps', 'posting', 'angry', 'political', 'stuff', 'posting', 'photos', 'baby', 'reposting', 'photos', 'newborn', 'like', '800', 'friends', 'gets', 'lot', 'interaction', 'posts', 'lot', 'friends', 'weirdos', 'actual', 'pervs', 'hes', 'major', 'narcissist', 'doesnt', 'care', 'ask', 'take', 'stopped', 'sending', 'pictures', 'baby', 'realized', 'posting', 'dont', 'even', 'post', 'pictures', 'babies', 'face', 'social', 'media', 'dont', 'want', 'plastered', 'stupid', 'page', 'really', 'bothering', 'tried', 'reporting', 'theres', 'option', 'specific', 'issue', 'meta', 'fire', 'autofollowing', 'trump', 'vance', 'blocking', 'democrat', 'hashtags', 'mark', 'zuckerberg', 'helping', 'institute', 'nationwide', 'abortion', 'ban', 'gilead', 'inching', 'closer', 'fruition', 'meta', 'agreed', 'pay', '25', 'million', 'sued', 'donald', 'trump', 'suspending', 'accounts', 'following', 'jan', '6', 'attack', 'capitol', 'meta', 'denies', 'forcing', 'accounts', 'follow', 'donald', 'trump', 'claims', 'hiding', 'democrat', 'hashtags', 'bug', 'users', 'arent', 'convinced', 'meta', 'mark', 'zuckerberg', 'youre', 'going', 'continue', 'bash', 'lgbtq', 'lgbtq', 'ever', 'supporting', 'disgust', 'gonna', 'allowed', 'specifically', 'lgbtq', 'allowed', 'piece', 'shit', 'guy', 'allow', 'people', 'disrespect', 'people', 'based', 'sexuality', 'people', 'concerned', 'peoples', 'lifestyles', 'boycottmeta', 'even', 'fair', 'share', '2024', 'olympic', 'games', 'satanic', 'monstrosities', 'banned', 'nudity', 'forced', 'watch', 'television', 'switched', 'kids', 'dont', 'need', 'see', 'important', 'psa', 'someone', 'reddit', 'sends', 'message', 'chat', 'saying', 'help', 'get', 'account', 'back', 'want', 'login', 'information', 'scam', 'take', 'screenshot', 'report', 'reddit', 'admins', 'send', 'modmail', 'us', 'please', 'note', 'mod', 'team', 'rfacebook', 'way', 'shape', 'form', 'associated', 'facebook', 'cannot', 'help', 'anything', 'facebook', 'related', 'nbsp', 'understand', 'desperation', 'issues', 'facebook', 'automated', 'process', 'suspend', 'account', 'end', 'flagging', 'many', 'people', 'legitimate', 'accounts', 'post', 'looking', 'help', 'people', 'take', 'advantage', 'fact', 'reach', 'reddit', 'assure', 'anyone', 'telling', 'help', 'hack', 'way', 'getting', 'service', 'back', 'help', 'get', 'personal', 'information', 'period', 'fall', 'take', 'screenshot', 'report', 'admins', 'send', 'us', 'modmail', 'clicking', 'link', 'require', 'screenshot', 'windows', 'click', 'windows', 'key', 'type', 'snip', 'use', 'snip', 'tool', 'go', 'provide', 'us', 'link']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>posts</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>help</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anyone</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Frequency\n",
       "0  facebook         25\n",
       "1     posts          9\n",
       "2        im          9\n",
       "3      help          9\n",
       "4    anyone          8"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))  # Load English stopwords\n",
    "words = [w for w in words if w not in stop_words]\n",
    "print(words)\n",
    "word_freq_counts = Counter(words)\n",
    "most_common = word_freq_counts.most_common(20)  \n",
    "\n",
    "common_words_df = pd.DataFrame(most_common, columns=['Word', 'Frequency'])\n",
    "common_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((anyone, else), 3)</td>\n",
       "      <td>((like, facebook, groups), 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((facebook, without), 2)</td>\n",
       "      <td>((take, screenshot, report), 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((like, facebook), 2)</td>\n",
       "      <td>((true, hardly, anyone), 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((facebook, groups), 2)</td>\n",
       "      <td>((hardly, anyone, uses), 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((dont, want), 2)</td>\n",
       "      <td>((anyone, uses, facebook), 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bigrams                         trigrams\n",
       "0       ((anyone, else), 3)    ((like, facebook, groups), 2)\n",
       "1  ((facebook, without), 2)  ((take, screenshot, report), 2)\n",
       "2     ((like, facebook), 2)      ((true, hardly, anyone), 1)\n",
       "3   ((facebook, groups), 2)      ((hardly, anyone, uses), 1)\n",
       "4         ((dont, want), 2)    ((anyone, uses, facebook), 1)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# Generate unigrams, bigrams, trigrams\n",
    "unigrams = list(ngrams(words, 1))\n",
    "bigrams = list(ngrams(words, 2))\n",
    "trigrams = list(ngrams(words, 3))\n",
    "\n",
    "# Count most common n-grams\n",
    "\n",
    "grams_df = pd.DataFrame()\n",
    "grams_df[\"bigrams\"] = Counter(bigrams).most_common(20)\n",
    "grams_df[\"trigrams\"] = Counter(trigrams).most_common(20)\n",
    "grams_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So bascailly, in addidtion to the relvent data from data frame, i also need to give \n",
    "#### Bigrams, trigrams, most coommon words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.4215\n",
      "1     0.9595\n",
      "2    -0.8555\n",
      "3     0.3268\n",
      "4     0.2500\n",
      "5    -0.4381\n",
      "6     0.9594\n",
      "7    -0.3438\n",
      "8     0.7248\n",
      "9    -0.8311\n",
      "10    0.1395\n",
      "11   -0.5574\n",
      "12   -0.6491\n",
      "13   -0.6124\n",
      "14   -0.3400\n",
      "15   -0.3400\n",
      "16   -0.7398\n",
      "17   -0.8034\n",
      "18   -0.5789\n",
      "19    0.0731\n",
      "Name: combined_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "sent = df['combined_text'].apply(lambda post: sia.polarity_scores(post)['compound'])\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentiment\"] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair</th>\n",
       "      <th>body</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>character_count</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Seperated_List</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>is it true hardly anyone uses facebook anymore...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>07:30:01</td>\n",
       "      <td>200</td>\n",
       "      <td>217</td>\n",
       "      <td>Discussion</td>\n",
       "      <td></td>\n",
       "      <td>is it true hardly anyone uses facebook anymore...</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>[is, it, true, hardly, anyone, uses, facebook,...</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>found out how to customize what you see on fac...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>21:56:19</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>its not perfect but go to where your settings ...</td>\n",
       "      <td>found out how to customize what you see on fac...</td>\n",
       "      <td>357</td>\n",
       "      <td>68</td>\n",
       "      <td>[found, out, how, to, customize, what, you, se...</td>\n",
       "      <td>0.9595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>facebook groups are full of bots  scams and fa...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>19:00:24</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>does anyone else feel like facebook groups are...</td>\n",
       "      <td>facebook groups are full of bots  scams and fa...</td>\n",
       "      <td>261</td>\n",
       "      <td>49</td>\n",
       "      <td>[facebook, groups, are, full, of, bots, scams,...</td>\n",
       "      <td>-0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>is there any point to hide allfrom the constan...</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>15:14:16</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>when fb went to hell a month or two ago i thou...</td>\n",
       "      <td>is there any point to hide allfrom the constan...</td>\n",
       "      <td>452</td>\n",
       "      <td>90</td>\n",
       "      <td>[is, there, any, point, to, hide, allfrom, the...</td>\n",
       "      <td>0.3268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>why do things i post on someone elses timeline...</td>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>00:46:54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Tech Support</td>\n",
       "      <td>for the past couple of months when i post a bi...</td>\n",
       "      <td>why do things i post on someone elses timeline...</td>\n",
       "      <td>421</td>\n",
       "      <td>83</td>\n",
       "      <td>[why, do, things, i, post, on, someone, elses,...</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month                                              title        date  \\\n",
       "0  2025-03  is it true hardly anyone uses facebook anymore...  2025-03-05   \n",
       "1  2025-03  found out how to customize what you see on fac...  2025-03-05   \n",
       "2  2025-03  facebook groups are full of bots  scams and fa...  2025-03-05   \n",
       "3  2025-03  is there any point to hide allfrom the constan...  2025-03-05   \n",
       "4  2025-03  why do things i post on someone elses timeline...  2025-03-06   \n",
       "\n",
       "       time  score  num_comments         flair  \\\n",
       "0  07:30:01    200           217    Discussion   \n",
       "1  21:56:19      7            23    Discussion   \n",
       "2  19:00:24      8             8    Discussion   \n",
       "3  15:14:16     13            23    Discussion   \n",
       "4  00:46:54      1             2  Tech Support   \n",
       "\n",
       "                                                body  \\\n",
       "0                                                      \n",
       "1  its not perfect but go to where your settings ...   \n",
       "2  does anyone else feel like facebook groups are...   \n",
       "3  when fb went to hell a month or two ago i thou...   \n",
       "4  for the past couple of months when i post a bi...   \n",
       "\n",
       "                                       combined_text  character_count  \\\n",
       "0  is it true hardly anyone uses facebook anymore...               74   \n",
       "1  found out how to customize what you see on fac...              357   \n",
       "2  facebook groups are full of bots  scams and fa...              261   \n",
       "3  is there any point to hide allfrom the constan...              452   \n",
       "4  why do things i post on someone elses timeline...              421   \n",
       "\n",
       "   Word_count                                     Seperated_List  Sentiment  \n",
       "0          14  [is, it, true, hardly, anyone, uses, facebook,...     0.4215  \n",
       "1          68  [found, out, how, to, customize, what, you, se...     0.9595  \n",
       "2          49  [facebook, groups, are, full, of, bots, scams,...    -0.8555  \n",
       "3          90  [is, there, any, point, to, hide, allfrom, the...     0.3268  \n",
       "4          83  [why, do, things, i, post, on, someone, elses,...     0.2500  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###-------------------------------------------------------CHATGPT COPY PASTE HO I AINT TAKING NO ACCOUNTABILITY-----------------------------------------------------\n",
    "\n",
    "\n",
    "# # Assuming the DataFrame is already loaded as df\n",
    "# # # Create a new column for post length (character count in the 'body' column)\n",
    "# df['post_length'] = df['body'].apply(len)\n",
    "\n",
    "# # Extract hour from the 'time' column\n",
    "# df['hour'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# # Analyze sentiment vs post length\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(data=df, x='post_length', y='Sentiment')\n",
    "# plt.title('Sentiment vs Post Length')\n",
    "# plt.xlabel('Post Length')\n",
    "# plt.ylabel('Sentiment')\n",
    "# plt.show()\n",
    "\n",
    "# # Analyze sentiment vs time of day\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(data=df, x='hour', y='Sentiment')\n",
    "# plt.title('Sentiment vs Time of Day')\n",
    "# plt.xlabel('Hour of Day')\n",
    "# plt.ylabel('Sentiment')\n",
    "# plt.show()\n",
    "\n",
    "# # Analyze sentiment vs popularity (score and num_comments)\n",
    "# df['popularity'] = df['score'] + df['num_comments']\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(data=df, x='popularity', y='Sentiment')\n",
    "# plt.title('Sentiment vs Popularity (Score + Comments)')\n",
    "# plt.xlabel('Popularity (Score + Comments)')\n",
    "# plt.ylabel('Sentiment')\n",
    "# plt.show()\n",
    "\n",
    "# # Correlations (Post length, Time, Popularity with Sentiment)\n",
    "# correlations = df[['post_length', 'hour', 'popularity', 'Sentiment']].corr()\n",
    "# print(correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['post_length', 'hour', 'popularity'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[230], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m relevant_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_comments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflair\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharacter_count\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWord_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_length\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopularity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrelevant_columns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m new_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\third\\OneDrive\\Desktop\\dataproject\\Reddit_Historical_Analysis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\third\\OneDrive\\Desktop\\dataproject\\Reddit_Historical_Analysis\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\third\\OneDrive\\Desktop\\dataproject\\Reddit_Historical_Analysis\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['post_length', 'hour', 'popularity'] not in index\""
     ]
    }
   ],
   "source": [
    "relevant_columns = ['date', 'score', 'num_comments', 'flair','character_count','Word_count', 'Sentiment','post_length','hour', \"popularity\"]\n",
    "new_df = df[relevant_columns]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "path = \"../../data/PostEDA\"\n",
    "processed_dir = path\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Convert DataFrames to dictionaries or lists of dictionaries\n",
    "with open(os.path.join(processed_dir, 'relevent_dataframe.json'), 'w') as f:\n",
    "    json.dump(new_df.to_dict(orient='records'), f, indent=2)\n",
    "\n",
    "with open(os.path.join(processed_dir, 'ngrams.json'), 'w') as f:\n",
    "    json.dump(grams_df.to_dict(orient='records'), f, indent=2)\n",
    "\n",
    "with open(os.path.join(processed_dir, 'most_common_words.json'), 'w') as f:\n",
    "    json.dump(common_words_df.to_dict(orient='records'), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
